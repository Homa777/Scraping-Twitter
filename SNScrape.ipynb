{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed6b44a5",
   "metadata": {},
   "source": [
    "## Install Snscraper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f92c957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snscrape requires at least Python 3.8 or higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0406f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b4e209f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "import numpy as np \n",
    "\n",
    "import snscrape.modules.twitter as sntwitter \n",
    "\n",
    "import datetime \n",
    "\n",
    "from tqdm.notebook import tqdm_notebook \n",
    "\n",
    "import seaborn as sns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1ace986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define any query based on your requirement\n",
    "# I used ChatGPT as keyword to find any comments asked by users containing this word. \n",
    "# I also scrape the comments from 01/01/2022 to 17/03/2023 and asked for 5000 comments in the mentined date.\n",
    "# You can search any query or any date based on your demand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed7c4c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\") \n",
    "text = \"ChatGPT\"\n",
    "username =''\n",
    "since = '2022-01-01'\n",
    "until='2023-03-17'\n",
    "count = int(5000)\n",
    "# retweet = input('Exclude Retweets? (y/n): ') \n",
    "# replies = input('Exclude Replies? (y/n): ') \n",
    "replies = 'y' \n",
    "retweet = 'n' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70237242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a search function which takes in the following inputs (text,username,since,until,retweet,replies) as arguments and creates a query string to be passed inside SNS twitter search scraper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5eeecbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(text,username,since,until,retweet,replies): \n",
    "\n",
    "    global filename \n",
    "\n",
    "    q=text\n",
    "\n",
    "    if username!='': \n",
    "\n",
    "      q += f\" from:{username}\"\n",
    "\n",
    "\n",
    "    if until=='': \n",
    "\n",
    "        until = datetime.datetime.strftime(datetime.date.today(), '%Y-%m-%d') \n",
    "\n",
    "        q += f\" until:{until}\" \n",
    "\n",
    "    if since=='':\n",
    "\n",
    "        since = datetime.datetime.strftime(datetime.datetime.strptime(until, '%Y-%m-%d') -datetime.timedelta(days=7), '%Y-%m-%d') \n",
    "\n",
    "        q += f\" since:{since}\" \n",
    "\n",
    "    if retweet == 'y': \n",
    "\n",
    "        q += f\" exclude:retweets\" \n",
    "\n",
    "    if replies == 'y': \n",
    "\n",
    "        q += f\" exclude:replies\" \n",
    "\n",
    "    if username!='' and text!='': \n",
    "\n",
    "        filename = f\"{since}_{until}_{username}_{text}.csv\" \n",
    "\n",
    "    elif username!=\"\": \n",
    "\n",
    "      filename = f\"{since}_{until}_{username}.csv\" \n",
    "    else: \n",
    "\n",
    "      filename = f\"{since}_{until}_{text}.csv\" \n",
    "\n",
    "      print(f\"Filename: {filename}\") \n",
    "\n",
    "      print(f\"Query: {q}\")\n",
    "\n",
    "    return q "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10caa5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling  above function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ac6d788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: 2022-01-01_2023-03-17_ChatGPT.csv\n",
      "Query: ChatGPT exclude:replies\n"
     ]
    }
   ],
   "source": [
    "P = search(text,username,since,until,retweet,replies) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e5b7c19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93a57c5b517e4da78cc3364753d52822",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating list to append tweet data  \n",
    "\n",
    "tweets_list1 = [] \n",
    "\n",
    " \n",
    "\n",
    "# Using TwitterSearchScraper to scrape data and append tweets to list \n",
    "\n",
    "if count == -1: \n",
    "\n",
    "    for i,tweet in enumerate(tqdm_notebook(sntwitter.TwitterSearchScraper(P).get_items())): \n",
    "\n",
    "        tweets_list1.append([tweet.date, tweet.id, tweet.rawContent, tweet.user.username,tweet.lang, tweet.hashtags,tweet.replyCount,tweet.retweetCount, tweet.likeCount,tweet.quoteCount,tweet.media]) \n",
    "\n",
    "else: \n",
    "\n",
    "    with tqdm_notebook(total=count) as pbar: \n",
    "\n",
    "      for i,tweet in enumerate(sntwitter.TwitterSearchScraper(P).get_items()): #declare a username  \n",
    "          if i>=count: #number of tweets you want to scrape \n",
    "            break \n",
    "\n",
    "          tweets_list1.append([ tweet.id, tweet.rawContent, tweet.user.username,tweet.lang,tweet.hashtags,tweet.replyCount, \n",
    "\n",
    "            tweet.retweetCount,tweet.likeCount,tweet.quoteCount,tweet.media]) \n",
    "\n",
    "          pbar.update(1) \n",
    "\n",
    "# Creating a dataframe from the tweets list above  \n",
    "\n",
    "tweets_df1 = pd.DataFrame(tweets_list1, columns=[ 'TweetId', 'Text', 'Username','Language', \n",
    "\n",
    "              'Hashtags','ReplyCount','RetweetCount','LikeCount','QuoteCount','Media']) \n",
    "tweets_df1.sort_values(by='TweetId',ascending=False) \n",
    "\n",
    "tweets_df1.to_csv(f\"{filename}\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb22239",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
